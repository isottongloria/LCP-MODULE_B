# LCP-MODULE_B
LCPB 21-22 Exercise 4, XGBoost
1.
Compare the performances of XGBoost with those of a feed-forward neural network (NN). Take a
labeled dataset (two categories) that is simple enough for analysis in a reasonable time. As usual,
separate the training and the test set.
Compare the accuracy of the two methods by varying the number of data samples in the training set.
2.
Try different parameters (λ, γ, n_estimators, …). Which is the simplest yet effective XGBoost model
that keeps a good accuracy?
